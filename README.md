# Explainable-AI
I successfully tackled the challenge of classifying YouTube video comments as either spam or legitimate using state-of-the-art Explainable AI techniques, namely LIME (Local Interpretable Model-agnostic Explanations) and SHAP (SHapley Additive exPlanations). Leveraging the YouTube02-Katy-Perry.csv dataset, I developed a machine learning model capable of making accurate predictions. What sets my project apart is the emphasis on transparency and interpretability; by employing LIME and SHAP, I not only achieved high accuracy but also provided insightful explanations for the model's decisions, ensuring that the classification process is not only reliable but also understandable to users and fellow developers. This project represents a significant step towards building AI systems that are not just intelligent but also accountable and comprehensible to the broader community.
